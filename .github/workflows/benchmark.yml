name: Performance Benchmarks

on:
  push:
    branches: [main]
    paths:
      - 'src/**'
      - 'tests/benchmarks/**'
      - 'package*.json'
      - 'vitest.bench.config.ts'
  pull_request:
    branches: [main]
    paths:
      - 'src/**'
      - 'tests/benchmarks/**'
  schedule:
    # Run benchmarks daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      benchmark_type:
        description: 'Benchmark type to run'
        required: false
        default: 'all'
        type: choice
        options:
        - all
        - performance
        - memory

jobs:
  benchmark:
    runs-on: ubuntu-latest
    
    strategy:
      matrix:
        node-version: [18, 20]
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        
      - name: Setup Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}
          cache: 'npm'
          
      - name: Install dependencies
        run: npm ci
        
      - name: Type check
        run: npm run typecheck
        
      - name: Run performance benchmarks
        if: ${{ github.event.inputs.benchmark_type == 'performance' || github.event.inputs.benchmark_type == 'all' || github.event.inputs.benchmark_type == '' }}
        run: |
          echo "Running performance benchmarks..."
          npm run bench:performance
        continue-on-error: true
        
      - name: Run memory benchmarks
        if: ${{ github.event.inputs.benchmark_type == 'memory' || github.event.inputs.benchmark_type == 'all' || github.event.inputs.benchmark_type == '' }}
        run: |
          echo "Running memory benchmarks..."
          npm run bench:memory
        continue-on-error: true
        
      - name: Run full benchmark suite
        if: ${{ github.event.inputs.benchmark_type == 'all' || github.event.inputs.benchmark_type == '' }}
        run: |
          echo "Running full benchmark suite..."
          npm run bench
        continue-on-error: true
        
      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: benchmark-results-node-${{ matrix.node-version }}
          path: |
            benchmark-results.json
            benchmark-*.json
          retention-days: 30
          
      - name: Comment benchmark results on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            
            // Read benchmark results if available
            let benchmarkComment = '## ðŸ“Š Benchmark Results\n\n';
            
            try {
              if (fs.existsSync('benchmark-results.json')) {
                const results = JSON.parse(fs.readFileSync('benchmark-results.json', 'utf8'));
                benchmarkComment += 'Performance benchmarks completed successfully.\n';
                benchmarkComment += `- Node.js version: ${{ matrix.node-version }}\n`;
                benchmarkComment += `- Total benchmarks: ${results?.benchmarks?.length || 'N/A'}\n`;
                benchmarkComment += '\n> Detailed results are available in the workflow artifacts.\n';
              } else {
                benchmarkComment += 'âš ï¸ Benchmark results file not found. Check workflow logs for details.\n';
              }
            } catch (error) {
              benchmarkComment += 'âŒ Failed to read benchmark results.\n';
              benchmarkComment += `Error: ${error.message}\n`;
            }
            
            // Find existing benchmark comment
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });
            
            const existingComment = comments.find(comment => 
              comment.body.includes('## ðŸ“Š Benchmark Results') && 
              comment.user.type === 'Bot'
            );
            
            if (existingComment) {
              // Update existing comment
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: existingComment.id,
                body: benchmarkComment
              });
            } else {
              // Create new comment
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: benchmarkComment
              });
            }
            
  benchmark-comparison:
    runs-on: ubuntu-latest
    needs: benchmark
    if: github.event_name == 'pull_request'
    
    steps:
      - name: Checkout base branch
        uses: actions/checkout@v4
        with:
          ref: ${{ github.base_ref }}
          
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20
          cache: 'npm'
          
      - name: Install dependencies
        run: npm ci
        
      - name: Run base benchmarks
        run: |
          echo "Running benchmarks on base branch..."
          npm run bench || true
        continue-on-error: true
        
      - name: Save base results
        run: |
          if [ -f "benchmark-results.json" ]; then
            mv benchmark-results.json base-benchmark-results.json
          fi
          
      - name: Checkout PR branch
        uses: actions/checkout@v4
        
      - name: Install PR dependencies
        run: npm ci
        
      - name: Run PR benchmarks
        run: |
          echo "Running benchmarks on PR branch..."
          npm run bench || true
        continue-on-error: true
        
      - name: Compare results
        run: |
          echo "Comparing benchmark results..."
          # This would ideally use a benchmark comparison tool
          # For now, just indicate that comparison is available
          echo "Base and PR benchmark results are available for comparison"
          ls -la *benchmark*.json || echo "No benchmark files found"
        
      - name: Upload comparison results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-comparison
          path: |
            *benchmark*.json
          retention-days: 7